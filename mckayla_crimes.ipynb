{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import itertools as it\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DR_NO', 'Date Rptd', 'DATE OCC', 'TIME OCC', 'AREA', 'AREA NAME', 'Rpt Dist No', 'Part 1-2', 'Mocodes', 'Vict Age', 'Vict Sex', 'Premis Cd', 'Premis Desc', 'Weapon Used Cd', 'Weapon Desc', 'LOCATION', 'Cross Street', 'LAT', 'LON', 'Crm Cd 1']\n",
      "67176\n"
     ]
    }
   ],
   "source": [
    "#DATA CLEANING CELL\n",
    "crime_data = pd.read_csv('Crime_Data_from_2020_to_Present.csv')\n",
    "# print(len(my_data.columns))\n",
    "crime_data = crime_data.drop(columns=['Vict Descent','Status','Status Desc'])\n",
    "# print(len(my_data.columns))\n",
    "all_c = list(crime_data.columns)\n",
    "final = []\n",
    "for i in all_c:\n",
    "    if 'Crm' not in i:\n",
    "        final.append(i)\n",
    "final.append('Crm Cd 1')\n",
    "print(final)\n",
    "crime_data.dropna(inplace=True,subset=final)\n",
    "crime_data = crime_data[crime_data['LON'] != 0]\n",
    "crime_data = crime_data[crime_data['LAT'] != 0]\n",
    "\n",
    "print(len(crime_data))\n",
    "# CODE TO DROP CRIMES WITH ONLY A FEW INCIDENTS\n",
    "X = crime_data.drop(columns=['Crm Cd 1', 'Crm Cd 2', 'Crm Cd 3', 'Crm Cd 4', 'Crm Cd'])\n",
    "y = crime_data['Crm Cd']\n",
    "# allowed number of crime incidents to keep in data\n",
    "num_incidents = 100\n",
    "crimes = []\n",
    "for i in set(y):\n",
    "    if len(crime_data[crime_data['Crm Cd']==i])>num_incidents:\n",
    "        crimes.append(i)\n",
    "\n",
    "new_df = crime_data[crime_data['Crm Cd'].isin(crimes)]\n",
    "new_df = pd.get_dummies(new_df, drop_first=True, columns=[\"Vict Sex\"],dtype = int)\n",
    "new_df['Vict Sex'] = new_df['Vict Sex_H'] + 2*new_df['Vict Sex_M'] + 3*new_df['Vict Sex_X']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DR_NO',\n",
       " 'Date Rptd',\n",
       " 'DATE OCC',\n",
       " 'TIME OCC',\n",
       " 'AREA',\n",
       " 'AREA NAME',\n",
       " 'Rpt Dist No',\n",
       " 'Part 1-2',\n",
       " 'Crm Cd',\n",
       " 'Crm Cd Desc',\n",
       " 'Mocodes',\n",
       " 'Vict Age',\n",
       " 'Premis Cd',\n",
       " 'Premis Desc',\n",
       " 'Weapon Used Cd',\n",
       " 'Weapon Desc',\n",
       " 'Crm Cd 1',\n",
       " 'Crm Cd 2',\n",
       " 'Crm Cd 3',\n",
       " 'Crm Cd 4',\n",
       " 'LOCATION',\n",
       " 'Cross Street',\n",
       " 'LAT',\n",
       " 'LON',\n",
       " 'Vict Sex_H',\n",
       " 'Vict Sex_M',\n",
       " 'Vict Sex_X',\n",
       " 'Vict Sex']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(new_df.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['TIME OCC','AREA','Rpt Dist No','Vict Age','Vict Sex','Weapon Used Cd','LAT','LON']\n",
    "labels = new_df['Crm Cd 1']\n",
    "X, X_test, y, y_test = train_test_split(new_df[features], labels,random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best(criterion=\"aic\"):\n",
    "    features = ['TIME OCC','AREA','Rpt Dist No','Vict Age','Vict Sex','Weapon Used Cd','LAT','LON']\n",
    "    labels = new_df['Crm Cd 1']\n",
    "    X, X_test, y, y_test = train_test_split(new_df[features], labels,random_state=2)\n",
    "    train = X\n",
    "    X1 = train[features].values\n",
    "    results = GradientBoostingClassifier(max_features=15).fit(X1,y)\n",
    "    crit = results.score(X_test[features],y_test)\n",
    "    best_score = crit\n",
    "    best_f = features\n",
    "\n",
    "    for k in tqdm(range(1,len(features))):\n",
    "        for combo in it.combinations(features,k):\n",
    "            print(train.columns)\n",
    "            X1 = train[combo].values\n",
    "            results = GradientBoostingClassifier(max_features=15).fit(X1,y)\n",
    "            crit = results.score(X_test[features],y_test)\n",
    "            if crit > best_score:\n",
    "                best_score = crit\n",
    "                best_f = combo\n",
    "    return best_score,best_f\n",
    "    # print(f\"best: {best[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score, best_f = find_best()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, X_test, y, y_test = train_test_split(new_df[features], labels,random_state=2)\n",
    "X = X[best_f]\n",
    "X_test = X[best_f]\n",
    "\n",
    "loss = ['log_loss']\n",
    "n_estimators = [50,100]\n",
    "max_depth = [1,9]\n",
    "min_samples_leaf = [1,4,8]\n",
    "\n",
    "max_loss = 0\n",
    "max_n = 0\n",
    "max_d = 0\n",
    "max_leaf = 0\n",
    "best_score = 0\n",
    "\n",
    "for l in loss:\n",
    "  for n in n_estimators:\n",
    "    for md in max_depth:\n",
    "      for ml in min_samples_leaf:\n",
    "        model = GradientBoostingClassifier(loss = l, n_estimators = n, max_depth = md, min_samples_leaf = ml,max_features=10)\n",
    "        model.fit(X,y)\n",
    "        score = model.score(X_test,y_test)\n",
    "        if score > best_score:\n",
    "          max_loss = l\n",
    "          max_n = n\n",
    "          max_d = md\n",
    "          max_leaf = ml\n",
    "          best_score = score\n",
    "print(\"Best Loss:\", max_loss)\n",
    "print(\"Best n_estimators:\", max_n)\n",
    "print(\"Best max_d:\", md)\n",
    "print(\"Best min_samples_leaf:\", max_leaf)\n",
    "print(\"Best Score:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = ['quantile', 'huber', 'squared_error', 'absolute_error']\n",
    "n_estimators = [50,100]\n",
    "max_depth = [1,9]\n",
    "min_samples_leaf = [1,4,8]\n",
    "\n",
    "max_loss = 0\n",
    "max_n = 0\n",
    "max_d = 0\n",
    "max_leaf = 0\n",
    "best_score = 0\n",
    "\n",
    "for l in loss:\n",
    "  for n in n_estimators:\n",
    "    for md in max_depth:\n",
    "      for ml in min_samples_leaf:\n",
    "        model = GradientBoostingRegressor(loss = l, n_estimators = n, max_depth = md, min_samples_leaf = ml,max_features=10)\n",
    "        model.fit(X,y)\n",
    "        score = model.score(X_test,y_test)\n",
    "        if score > best_score:\n",
    "          max_loss = l\n",
    "          max_n = n\n",
    "          max_d = md\n",
    "          max_leaf = ml\n",
    "          best_score = score\n",
    "print(\"Best Loss:\", max_loss)\n",
    "print(\"Best n_estimators:\", max_n)\n",
    "print(\"Best max_d:\", md)\n",
    "print(\"Best min_samples_leaf:\", max_leaf)\n",
    "print(\"Best Score:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = xgb.XGBClassifier(objective = 'multi:softmax')\n",
    "# Specify values for certain hyperparameters\n",
    "param_grid = {\"alpha\": [1,3,5],\n",
    "                 \"gamma\": [1,3,5],\n",
    "                 \"lambda\": [1,3,5,7],\n",
    "                 \"eta\": [.3,.5,.9]}\n",
    "knn_gs = GridSearchCV(knn, param_grid,cv=2)\n",
    "# Run the actual search. This may take some time.\n",
    "knn_gs.fit(X, y)\n",
    "# After fitting, you can access data about the results.\n",
    "print('best paramaters: ' + str(knn_gs.best_params_), 'best score: ' +str(knn_gs.best_score_), sep='\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.13 ('acme')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f9667e94c5242b6e179d4931e51f0ea8382a201d07ce0883b2e989376c502410"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
